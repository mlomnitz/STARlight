{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle cross-section studies\n",
    "This notebook \"automates\" the procedure used to obtain particle cross-sections for electro- and photo-production at the different colliders. This works for both _ep_ and _eA_, where _A_ is the corresponding heavy-ion target at the different colliders. \n",
    "The colliders are defined as follows:\n",
    "- eRHIC: 18 GeV electrons on 275 GeV protons or 100 GeV/n Gold\n",
    "- JLEIC: 10 GeV electrons on 100 GeV protons or 40 GeV/n Lead\n",
    "- LHeC: 60 GeV electrons  on 7 TeV protons or 2.8 TeV/n Lead\n",
    "- CEBAF: Fixed target exepriment, 12 GeV electrons on protons or Lead\n",
    "- HERA: 27.5 GeV electrons on protons\n",
    "\n",
    "First we load the relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sys, string, os\n",
    "from math import log10, floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables\n",
    "Define some global variables for the production, e.g. working directory, particle id's and associated names, units used for decoding the log files, etc.\n",
    "\n",
    "*Note*: It is assumed that home_dir contains eSTARlight and the compiled executable e_starlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home_dir = '/Users/michaellomnitz/Documents/install_test/'\n",
    "particle_id = [ 113, 333, 443011, 444011, 553011]\n",
    "#particle_id = [ 444011, 553011]\n",
    "particle_name = ['rho', 'phi', 'J_psi', 'Psi_2s', 'Upsilon_1s']\n",
    "#particle_name = [ 'Psi_2s', 'Upsilon_1s']\n",
    "unit_decode = { 'mb.':-3, 'microb.':-6, 'nanob.':-9, 'picob.':-12, 'femtob.':-15}\n",
    "unit_latex = { 'mb.':'mb', 'microb.':'$\\mu$b', 'nanob.':'nb', 'picob.':'pb', 'femtob.':'fb'}\n",
    "event_unit = { 3:'K', 6:'M', 9:'G'}\n",
    "n_events_from_units = {'mb.':'T', 'microb.':'G', 'nanob.':'M', 'picob.':'K', 'femtob.':''} #considering 1 fb^-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions\n",
    "Some simple funcitons used for utilies and run workflow:\n",
    "- round_sig: Round a number to a given number of significant figures\n",
    "- make_input_file: Takes template input file for _eSTARlight_ and sets the desired $Q^2$ range and target nucleii.\n",
    "- run_accel_study: Iterates over particle species for both photo-($Q^2$ < 1 \\rm{GeV}$) and electro-(1< $Q^2$ < 100 \\rm{GeV}$ and calls _eSTARlight_. The log file is then saved to desired location\n",
    "- decode_string: Takes relevant line from _eSTARlight_ and extract the cross-section and units (i.e. reads \"gamma+X --> VM+X 204.161 microb.\" and returns $204.161\\times10^{-6}$)\n",
    "- find_x_section: Iterates over produced log files and extracts cross-sections\n",
    "- make_table_line: Prints the table as would be formatted for a paper table table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def round_sig(x, sig=2):\n",
    "    if x < 1e-6:\n",
    "        return 0\n",
    "    return round(x, sig-int(floor(log10(abs(x))))-1)\n",
    "\n",
    "def make_input_file(prod_no,prod_mech, template_loc):\n",
    "    #load template\n",
    "    with open(template_loc,'r') as f:\n",
    "        data = f.readlines()\n",
    "    # --  Set prodiction id\n",
    "    data[29] = 'PROD_PID = '+str(particle_id[prod_no])+'   #Channel of interest; this is '+str(particle_name[prod_no])+'\\n'\n",
    "    if prod_mech is 'PP':\n",
    "        data[33] = 'MIN_GAMMA_Q2 = 0. \\n'\n",
    "        data[34] = 'MAX_GAMMA_Q2 = 1.0 \\n'\n",
    "    if prod_mech is 'EP':\n",
    "        data[33] = 'MIN_GAMMA_Q2 = 1.0 \\n'\n",
    "        data[34] = 'MAX_GAMMA_Q2 = 100.0 \\n'\n",
    "    with open(home_dir+'slight.in','w') as f:\n",
    "        f.writelines(data)\n",
    "\n",
    "def run_accel_study(accel_name, pwd_to_template):\n",
    "    print(len(particle_id),' particles in study')\n",
    "    output_dir = home_dir+'eSTARlight/production/accel_x_secs/'+accel_name\n",
    "    if os.path.isdir(output_dir) is False:\n",
    "        os.makedirs(output_dir)\n",
    "        os.makedirs(output_dir+'/PP')\n",
    "        os.makedirs(output_dir+'/EP')\n",
    "    for idx,part in enumerate(particle_id):\n",
    "        make_input_file(idx,'PP',pwd_to_template)\n",
    "        os.chdir( home_dir )\n",
    "        os.system( home_dir+'e_starlight > log' )\n",
    "        os.rename(home_dir+'log',output_dir+'/PP/x_section_'+particle_name[idx]+'.txt')\n",
    "        #\n",
    "        #print('Finished with ',particle_name[idx],' photo-production')\n",
    "        make_input_file(idx,'EP',pwd_to_template)\n",
    "        os.chdir( home_dir )\n",
    "        os.system( home_dir+'e_starlight > log' )\n",
    "        os.rename(home_dir+'log',output_dir+'/EP/x_section_'+particle_name[idx]+'.txt')\n",
    "    \n",
    "def decode_string( line ):\n",
    "    space_pos = [pos for pos,char in enumerate(line) if char == ' ']\n",
    "    n_space = len(space_pos)\n",
    "    #print(line[space_pos[n_space-2]:space_pos[n_space-1]])\n",
    "    num = float(line[space_pos[n_space-2]:space_pos[n_space-1]])\n",
    "    num = round_sig(num,2)\n",
    "    units = line[space_pos[n_space-1]+1:-1]\n",
    "    return num,units\n",
    "    \n",
    "def find_x_section(accel_name, prod_mech, part_id):\n",
    "    file_loc = home_dir+'eSTARlight/production/accel_x_secs/'\n",
    "    file_loc = file_loc+accel_name+'/'+prod_mech+'/x_section_'+particle_name[part_id]+'.txt'\n",
    "    with open(file_loc,'r') as f:\n",
    "        data = f.readlines()\n",
    "    nline = 0\n",
    "    for i in range(len(data)):\n",
    "        if \"Total cross section\" in data[i]:\n",
    "            nline = i\n",
    "    x_sec, units = decode_string(data[nline])\n",
    "    return x_sec, units\n",
    "\n",
    "def make_table_line(collision_system, prod_mech, target_A):\n",
    "    particle_row = ''\n",
    "    x_sec_row = ' & '\n",
    "    rate_row = ''\n",
    "    for idx, a in enumerate(particle_name):\n",
    "        x_sec, units = find_x_section(collision_system, prod_mech, idx)\n",
    "        n_events = round(10*x_sec/target_A,2)\n",
    "        particle_row+=a+' & '\n",
    "        x_sec_row+='$'+str(x_sec)+'$ '+unit_latex[units]+' & '\n",
    "        rate_row+= str(n_events)+n_events_from_units[units]\n",
    "        if idx != len(particle_name)-1:\n",
    "            rate_row+=' & '\n",
    "        else:\n",
    "            rate_row+='\\\\\\\\'\n",
    "    return x_sec_row+rate_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----  JLEIC  ----  /Users/michaellomnitz/Documents/install_test/eSTARlight/production/templates/slight_template_JLEIC.in\n",
      "5  particles in study\n",
      " ----  eRHIC  ----  /Users/michaellomnitz/Documents/install_test/eSTARlight/production/templates/slight_template_eRHIC.in\n",
      "5  particles in study\n",
      " ----  LHeC  ----  /Users/michaellomnitz/Documents/install_test/eSTARlight/production/templates/slight_template_LHeC.in\n",
      "5  particles in study\n",
      " ----  JLEIC_eA  ----  /Users/michaellomnitz/Documents/install_test/eSTARlight/production/templates/slight_template_JLEIC_eA.in\n",
      "5  particles in study\n",
      " ----  eRHIC_eA  ----  /Users/michaellomnitz/Documents/install_test/eSTARlight/production/templates/slight_template_eRHIC_eA.in\n",
      "5  particles in study\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/michaellomnitz/Documents/install_test/log' -> '/Users/michaellomnitz/Documents/install_test/eSTARlight/production/accel_x_secseRHIC_eA/EP/x_section_Psi_2s.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-53c4e222bf07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtemlate_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhome_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'eSTARlight/production/templates/slight_template_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.in'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' ---- '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' ---- '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemlate_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrun_accel_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemlate_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-729b50f71111>\u001b[0m in \u001b[0;36mrun_accel_study\u001b[0;34m(accel_name, pwd_to_template)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mhome_dir\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mhome_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'e_starlight > log'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/EP/x_section_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mparticle_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_string\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/michaellomnitz/Documents/install_test/log' -> '/Users/michaellomnitz/Documents/install_test/eSTARlight/production/accel_x_secseRHIC_eA/EP/x_section_Psi_2s.txt'"
     ]
    }
   ],
   "source": [
    "detectors = ['JLEIC', 'eRHIC', 'LHeC','JLEIC_eA', 'eRHIC_eA', 'LHeC_eA']\n",
    "for det in detectors:\n",
    "    temlate_loc = home_dir+'eSTARlight/production/templates/slight_template_'+det+'.in'\n",
    "    print(' ---- ',det,' ---- ', temlate_loc)\n",
    "    run_accel_study(det,temlate_loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make paper tables\n",
    "Using the previously defined tables we can now pepare the tables for the paper. Define the individual rows with their associated rows and the correct scaling for the heavy-ion targets.  The function _make_full_table_ builds the table out of the previous functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_prod_rows = { 'eRHIC':['eRHIC - $ep$',1], 'eRHIC_eA':['eRHIC - $eA$',197],\n",
    "               'JLEIC':['JLEIC - $ep$',1], 'JLEIC_eA':['JLEIC - $eA$',208],\n",
    "               'LHeC' :['LHeC - $ep$',1],  'LHEC_eA' :['LHeC - $eA$',208],\n",
    "             }\n",
    "def make_full_table( prod_mech ):\n",
    "    for idx,key in enumerate(_prod_rows):\n",
    "        #print(idx,_prod_rows[key][0])\n",
    "        to_print = _prod_rows[key][0] + make_table_line(key,prod_mech,_prod_rows[key][1])\n",
    "        print( to_print )\n",
    "        if (idx+1)%2 == 0:\n",
    "            print('\\hline')\n",
    "make_full_table('PP') # > 1 GeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eRHIC - $ep$ & $14.0$ nb & $1.7$ nb & $570.0$ pb & $120.0$ pb & $2.4$ pb & 140.0M & 17.0M & 5700.0K & 1200.0K & 24.0K\\\\\n",
      "eRHIC - $eA$ & $730.0$ nb & $110.0$ nb & $77.0$ nb & $19.0$ nb & $200.0$ pb & 37.06M & 5.58M & 3.91M & 0.96M & 10.15K\\\\\n",
      "\\hline\n",
      "JLEIC - $ep$ & $10.0$ nb & $1.2$ nb & $270.0$ pb & $55.0$ pb & $790.0$ fb & 100.0M & 12.0M & 2700.0K & 550.0K & 7900.0\\\\\n",
      "JLEIC - $eA$ & $450.0$ nb & $67.0$ nb & $25.0$ nb & $5.1$ nb & $0$ fb & 21.63M & 3.22M & 1.2M & 0.25M & 0.0\\\\\n",
      "\\hline\n",
      "LHeC - $ep$ & $26.0$ nb & $3.7$ nb & $2.9$ nb & $630.0$ pb & $18.0$ pb & 260.0M & 37.0M & 29.0M & 6300.0K & 180.0K\\\\\n",
      "LHeC - $eA$ & $2.0$ $\\mu$b & $340.0$ nb & $560.0$ nb & $150.0$ nb & $5.3$ nb & 0.1G & 16.35M & 26.92M & 7.21M & 0.25M\\\\\n",
      "\\hline\n",
      "CEBAF - $ep$ & $1.1$ nb & $64.0$ pb & $0$ fb & $0$ fb & $0$ fb & 11.0M & 640.0K & 0.0 & 0.0 & 0.0\\\\\n",
      "CEBAF - $ep$ & $0$ fb & $0$ fb & $0$ fb & $0$ fb & $0$ fb & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\\n",
      "\\hline\n",
      "HERA - $ep$ & $44.0$ nb & $6.4$ nb & $17.0$ nb & $3.6$ nb & $120.0$ pb & 440.0M & 64.0M & 170.0M & 36.0M & 1200.0K\\\\\n"
     ]
    }
   ],
   "source": [
    "make_full_table('EP') # < 1 GeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
